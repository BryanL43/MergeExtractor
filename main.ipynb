{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "&#160; THE PROPOSED BUYOUT &#160; 38.&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;On August 12, 2008, the Company announced that it had entered into a merger agreement with CVS\n",
      "Through this acquisition, CVS Caremark will acquire Longs&#8217; 521 retail drugstores in California, Hawaii, Nevada and Arizona as well as its Rx America subsidiary, which offers prescription benefits management (&#8220;PBM&#8221;) services to over 8 million members and prescription drug plan benefits to approximately 450,000 Medicare beneficiaries\n",
      "Further, the acquisition complements CVS Caremark&#8217;s substantial presence in Southern California and provides &#160; - 6 - COMPLAINT FOR BREACH OF FIDUCIARY DUTIES AND AIDING AND ABETTING &#160; a foundation for significant future growth throughout the nation&#8217;s largest state\n",
      "&#160; &#8220;With this acquisition, we will increase accessibility to our pharmacies for consumers and put us in an even better position to grow our new Proactive Pharmacy Care offerings with our PBM clients\n",
      "Assuming completion of the transaction in the fourth quarter of 2008, the acquisition is expected to be dilutive to earnings per share in the first year, and accretive to EPS beginning in 2010\n",
      "&#160; 41.&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;In response to questions from analysts on the accuracy of CVS&#8217;s synergies estimates, Ryan stated: &#160; Well, I&#8217;ll just say that I don&#8217;t think we&#8217;ve ever missed our projections on acquisition, either on the revenue side or the synergy side\n",
      "The &#8220;top-up&#8221; provides that (i) once CVS secures tender of at least 66.67% of the Company&#8217;s shares, (ii) CVS will have the right to purchase any and all additional shares from the Company treasury that it requires in order to control 90% of the Company&#8217;s shares and (iii) squeeze out the rest of the Company&#8217;s remaining public shareholders via a &#8220;short-form&#8221; merger\n",
      "Thus, because of the top-up, CVS will need only about 46% of rest of the Company&#8217;s publicly held shares in order the squeeze out the remaining minority shareholders in a short-form merger\n",
      "3.&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;The Proposed Buyout is an opportunistic transaction for defendants, as it allows industry competitor CVS to further consolidate the market and strengthen its position on the West Coast, Southwest and Hawaii following its acquisition of Caremark in 2007\n",
      "The &#8220;top-up&#8221; provides that (i) once CVS secures tender of at least 66.67% of the Company&#8217;s shares, (ii) CVS will have the right to purchase any and all additional shares from the Company treasury that it requires in order to control 90% of the Company&#8217;s shares and (iii) squeeze out the rest of the Company&#8217;s remaining public shareholders via a &#8220;short-form&#8221; merger\n",
      "Moreover, because the Proposed Buyout does not provide for an alternate remedy of appraisal for shareholders, these &#160; &#160; &#160; - 2 - AMENDED COMPLAINT FOR BREACH OF FIDUCIARY DUTIES AND AIDING AND ABETTING &#160; &#160; shareholders will have no choice but to tender their shares or get squeezed out on the back-end in a short-form merger even though they do not believe that the Proposed Buyout adequately values the Company&#8217;s shares\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import spacy\n",
    "\n",
    "# Step 1: Load the File\n",
    "def load_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        return file.read()\n",
    "\n",
    "# Step 2: Preprocess the Text to Remove HTML Tags\n",
    "def preprocess_text(content):\n",
    "    # Remove HTML tags and normalize whitespace\n",
    "    cleaned_text = re.sub(r'<.*?>', '', content)  # Remove all HTML tags\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text).strip()  # Normalize whitespace\n",
    "    return cleaned_text\n",
    "\n",
    "# Step 3: Extract Background Section Using NLP and Date Detection\n",
    "def extract_background_section(text, nlp_model):\n",
    "    # List of possible titles for background sections\n",
    "    possible_headings = [\n",
    "        'background of the merger', 'merger timeline', 'history of the merger',\n",
    "        'background to the proposed buyout', 'merger events', 'merger history', 'timeline'\n",
    "    ]\n",
    "    \n",
    "    # Look for the start of the section with any of the potential headings (case insensitive)\n",
    "    start_pattern = r'(' + '|'.join([re.escape(keyword) for keyword in possible_headings]) + r')'\n",
    "    match = re.search(start_pattern, text, re.IGNORECASE)\n",
    "    \n",
    "    if not match:\n",
    "        return \"Could not find a Background section.\"\n",
    "    \n",
    "    # Extract section text starting from the match (where background starts)\n",
    "    start_idx = match.end()\n",
    "    section_text = text[start_idx:]\n",
    "\n",
    "    # Define end conditions based on common next section titles\n",
    "    end_keywords = ['recommendation', 'board approval', 'conclusion', 'approval of the merger', 'terms of the merger']\n",
    "    \n",
    "    # Look for the end of the section by matching common keywords\n",
    "    for keyword in end_keywords:\n",
    "        end_pattern = r'\\b' + re.escape(keyword) + r'\\b'\n",
    "        end_match = re.search(end_pattern, section_text, re.IGNORECASE)\n",
    "        if end_match:\n",
    "            section_text = section_text[:end_match.start()]\n",
    "            break\n",
    "\n",
    "    return section_text.strip()\n",
    "\n",
    "# Step 4: Extract Chronological Events (timeline-like sentences)\n",
    "def extract_chronological_events(relevant_text):\n",
    "    # Regex to match date patterns (simple match for dates and month/year)\n",
    "    date_pattern = r'(\\b\\d{4}\\b|\\b(?:January|February|March|April|May|June|July|August|September|October|November|December)\\b\\s\\d{1,2},?\\s\\d{4})'\n",
    "    events = [sentence for sentence in relevant_text.split('. ') if re.search(date_pattern, sentence)]\n",
    "    return events\n",
    "\n",
    "# Step 5: Filter Events Using NLP\n",
    "def filter_events_with_nlp(events, nlp_model, context_keywords):\n",
    "    filtered_events = []\n",
    "    for event in events:\n",
    "        doc = nlp_model(event)\n",
    "        if any(token.lemma_ in context_keywords for token in doc):\n",
    "            filtered_events.append(event)\n",
    "    return filtered_events\n",
    "\n",
    "# Main Execution\n",
    "def main():\n",
    "    # Load the text file\n",
    "    file_path = './sample2.txt'\n",
    "    content = load_file(file_path)\n",
    "    cleaned_text = preprocess_text(content)\n",
    "\n",
    "    # Load spaCy model\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "    # Extract Background Section (timeline-like data)\n",
    "    background_section = extract_background_section(cleaned_text, nlp)\n",
    "    if background_section == \"Could not find a Background section.\":\n",
    "        print(background_section)\n",
    "        return\n",
    "\n",
    "    # Extract chronological events (timeline of the merger)\n",
    "    events = extract_chronological_events(background_section)\n",
    "\n",
    "    # Context keywords for NLP filtering (e.g., merger-related terms)\n",
    "    context_keywords = ['merge', 'acquire', 'acquisition', 'merger']\n",
    "\n",
    "    # Filter events with NLP\n",
    "    filtered_events = filter_events_with_nlp(events, nlp, context_keywords)\n",
    "\n",
    "    # Output filtered events (timeline)\n",
    "    for event in filtered_events:\n",
    "        print(event)\n",
    "\n",
    "# Run the script\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MergeExtractor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
