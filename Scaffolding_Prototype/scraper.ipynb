{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import time\n",
    "import json\n",
    "import sys\n",
    "import concurrent.futures\n",
    "import re\n",
    "from tqdm import tqdm # Progress bar for visualizing data cleaning progress\n",
    "\n",
    "# Defined global variables\n",
    "csvFile = \"./truncatedData.csv\";\n",
    "cikFile = \"./cik-lookup-data.txt\";\n",
    "minDate = datetime(2001, 1, 1);\n",
    "formTypes = [\"PREM14A\", \"S-4\", \"SC 14D9\", \"SC TO-T\"];\n",
    "mainIndex = 0;\n",
    "\n",
    "# Read the CSV file and extract the date & both merging companies (index base)\n",
    "filedDate = pd.read_csv(csvFile, header=None).iloc[:, 1].tolist();\n",
    "companyAList = pd.read_csv(csvFile, header=None).iloc[:, 2].tolist();\n",
    "companyBList = pd.read_csv(csvFile, header=None).iloc[:, 3].tolist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acquire the constraint of a given date.\n",
    "# Pad 2 months backward and forward for constraint.\n",
    "def getDateConstraints(date):\n",
    "    originalDate = datetime.strptime(date, \"%m/%d/%Y\");\n",
    "\n",
    "    # Define the lower-bound date\n",
    "    lbMonth = originalDate.month - 2;\n",
    "    if (lbMonth <= 0): # Case: Wrap to previous year\n",
    "        lbMonth += 12;\n",
    "        lbYear = originalDate.year - 1;\n",
    "    else: # Case: Still on current year\n",
    "        lbYear = originalDate.year;\n",
    "\n",
    "    # Construct lower-bound date\n",
    "    try:\n",
    "        lowerBoundDate = originalDate.replace(year=lbYear, month=lbMonth);\n",
    "    except ValueError: # Catch potential error i.e. feb. 30 not existing\n",
    "        lowerBoundDate = originalDate.replace(year=lbYear, month=lbMonth, day=1);\n",
    "\n",
    "    # Ensure the new date does not go below the minimum date\n",
    "    if (lowerBoundDate < minDate):\n",
    "        lowerBoundDate = minDate;\n",
    "\n",
    "    \n",
    "    # Define the upper-bound date\n",
    "    ubMonth = originalDate.month + 2;\n",
    "    if (ubMonth > 12): # Case: Wrap to next year\n",
    "        ubMonth -= 12;\n",
    "        ubYear = originalDate.year + 1;\n",
    "    else: # Case: Still on current year\n",
    "        ubYear = originalDate.year;\n",
    "\n",
    "    # Construct upper-bound date\n",
    "    try:\n",
    "        upperBoundDate = originalDate.replace(year=ubYear, month=ubMonth);\n",
    "    except ValueError: # Catch potential error i.e. feb. 30 not existing\n",
    "        upperBoundDate = originalDate.replace(year=ubYear, month=ubMonth + 1, day=1);\n",
    "\n",
    "    return [lowerBoundDate, upperBoundDate];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acquire the CIK for further filtering in document look-up\n",
    "def getCIKs(companyName):\n",
    "    cikList = [];\n",
    "\n",
    "    # Create a request that mimics browser activity\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36\",\n",
    "        \"Referer\": \"https://www.sec.gov/search-filings/cik-lookup\"\n",
    "    }\n",
    "\n",
    "    formData = {\n",
    "        \"company\": companyName\n",
    "    }\n",
    "\n",
    "    url = \"https://www.sec.gov/cgi-bin/cik_lookup\";\n",
    "\n",
    "    # Request the search query & acquire the DOM elements\n",
    "    response = requests.post(url, headers=headers, data=formData);\n",
    "    if (response.status_code != 200):\n",
    "        sys.exit(response.status_code);\n",
    "\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\");\n",
    "\n",
    "    # Extract the CIK from the DOM elements\n",
    "    preTag = soup.find_all(\"pre\");\n",
    "    if (len(preTag) >= 2):\n",
    "        preTag = preTag[1];\n",
    "        for anchor in preTag.find_all(\"a\"):\n",
    "            cikList.append(anchor.text.strip());\n",
    "    else:\n",
    "        print(\"ERROR: CIK not found!\");\n",
    "        sys.exit(1);\n",
    "    \n",
    "    return cikList;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acquire all the json documents for the given company\n",
    "def getDocumentJson(companyName, dateLB, dateUB, formTypes, cik):\n",
    "    url = f\"https://efts.sec.gov/LATEST/search-index?q={companyName}&dateRange=custom&category=custom&startdt={dateLB}&enddt={dateUB}&forms={formTypes}&filter_ciks={cik}\";\n",
    "    print(url);\n",
    "\n",
    "    # Create a request that mimics browser activity\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36\",\n",
    "        \"Referer\": \"https://www.sec.gov/\"\n",
    "    }\n",
    "\n",
    "    # Request the search query & acquire the DOM elements\n",
    "    response = requests.get(url, headers=headers);\n",
    "    if (response.status_code != 200):\n",
    "        print(\"FATAL: getDocumentJson response yielded an error!\");\n",
    "        sys.exit(response.status_code);\n",
    "    \n",
    "    data = response.json();\n",
    "    totalValue = data[\"hits\"][\"total\"][\"value\"];\n",
    "\n",
    "    if (totalValue > 0):\n",
    "        return data[\"hits\"][\"hits\"];\n",
    "    else:\n",
    "        return None;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formulate the source document links from the search result json\n",
    "def getSourceLinks(documentJson):\n",
    "    # Formulate all source document file links\n",
    "    sourceLinks = [];\n",
    "\n",
    "    # Iterate through each json object and construct the source document file links\n",
    "    for document in documentJson[0]:\n",
    "        try:\n",
    "            # Get the CIK id or if there is multiple, then acquire the last one\n",
    "            validatedCik = None;\n",
    "            ciks = document[\"_source\"][\"ciks\"];\n",
    "            if ciks:\n",
    "                lastCIK = ciks[-1];\n",
    "                validatedCik = lastCIK;\n",
    "\n",
    "            # Remove leading zeros from the CIK\n",
    "            validatedCik.lstrip('0');\n",
    "        \n",
    "            # Acquire normal adsh & adsh without the \"-\" character\n",
    "            adsh = document[\"_source\"][\"adsh\"];\n",
    "            truncatedADSH = document[\"_source\"][\"adsh\"].replace(\"-\", \"\");\n",
    "            \n",
    "            sourceLinks.append(f\"https://www.sec.gov/Archives/edgar/data/{validatedCik}/{truncatedADSH}/{adsh}.txt\");\n",
    "        except KeyError as e:\n",
    "            print(f\"Missing key in document: {e}, result: {document}\");\n",
    "            continue; # Skip the document if there is a missing key; logged for further investigation\n",
    "\n",
    "    return sourceLinks;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "- Apparently \"Cos\" as a 2nd word means \"Companies\" in the search query.\n",
    "- For CIK lookup, .com is replaced with Com.\n",
    "- For CIK lookup, remove content within parentheses.\n",
    "\"\"\"\n",
    "def restructCompanyName(companyName, use_url_encoding=False):\n",
    "    words = companyName.split()\n",
    "    if len(words) > 1 and words[1] == \"Cos\":\n",
    "        words[1] = \"Companies\"\n",
    "    \n",
    "    if not use_url_encoding:\n",
    "        words = [word.replace(\".com\", \" Com\") for word in words]\n",
    "        # Remove content within parentheses\n",
    "        companyName = re.sub(r'\\(.*?\\)', '', ' '.join(words)).strip()\n",
    "        words = companyName.split()\n",
    "    \n",
    "    separator = \"%20\" if use_url_encoding else \" \"\n",
    "    return separator.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def searchDocuments(searchCompany, pairCompany, dateLB, dateUB, formTypes):\n",
    "    restructName = restructCompanyName(searchCompany, use_url_encoding=True);\n",
    "\n",
    "    # Multi-thread the ciks to concurrently process https request for companyA\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        ciks = getCIKs(restructCompanyName(pairCompany, use_url_encoding=False));\n",
    "        results = list(executor.map(\n",
    "            getDocumentJson,\n",
    "            [restructName] * len(ciks),\n",
    "            [dateLB] * len(ciks),\n",
    "            [dateUB] * len(ciks),\n",
    "            [formTypes] * len(ciks),\n",
    "            ciks\n",
    "        ));\n",
    "\n",
    "    return results;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # for mainIndex in tqdm(range(len(companyAList)), desc=\"Scanning\", leave=False):\n",
    "    # Reconstruct the constraint date & form type for url parsing\n",
    "    constraintDates = getDateConstraints(filedDate[mainIndex]);\n",
    "    lbDate, ubDate = constraintDates;\n",
    "    restructLB = f\"{lbDate.year}-{lbDate.month:02}-{lbDate.day:02}\";\n",
    "    restructUB = f\"{ubDate.year}-{ubDate.month:02}-{ubDate.day:02}\";\n",
    "    restructForms = \"%2C\".join(formTypes).replace(\" \", \"%20\");\n",
    "\n",
    "    # We will first attempt to search for the \"Background of the Merger\" via companyA;\n",
    "    # if not found, then we will search for companyB.\n",
    "    results = searchDocuments(companyAList[mainIndex], companyBList[mainIndex], restructLB, restructUB, restructForms);\n",
    "    if all(result is None for result in results):\n",
    "        # Search for companyB documents\n",
    "        results = searchDocuments(companyBList[mainIndex], companyAList[mainIndex], restructLB, restructUB, restructForms);\n",
    "        if all(result is None for result in results):\n",
    "            print(\"No results found for index:\", mainIndex, \"; companies: \", companyAList[mainIndex], \" & \", companyBList[mainIndex]);\n",
    "\n",
    "    # for link in getSourceLinks(results):\n",
    "    #     print(link);\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MergeExtractor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
